---
title: "Historic District analysis"
author: "pete rodrigue"
date: "2025-08-28"
output: html_document
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE, message=F, warning=F, fig.width = 11.5, fig.height = 6.5)
# load required libraries
library(readr)
library(sf)
library(leaflet)
library(rstudioapi)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(plotly)
library(did)
```

Set working directory to the place this script is saved:

```{r}
# Getting the path of your current open file
current_path = rstudioapi::getActiveDocumentContext()$path 
setwd(dirname(current_path))
```


# Load and clean data


```{r}
# load & clean census tract data
# please see https://opendata.dc.gov/datasets/DCGIS::census-tracts-in-1970/about
# for example, for more details on variable names
load_clean_tracts <- function(geo_id_var, black_var, white_var, totpop_var, year) {
  # Function parameters:
  # geo_id_var: name of the column containing geographic identifiers (as string)
  # black_var: name of the column containing Black population count (as string)
  # white_var: name of the column containing White population count (as string)
  # totpop_var: name of the column containing total population count (as string)
  # year: the year of the census data (used in file path and as metadata)
  
  # Load the tract shapefile
  shp <- sf::st_read(paste0("tract_data/Census_Tracts_in_", year, 
                            "/Census_Tracts_in_", year, ".shp")) 
  # Clean and standardize the data
  shp <- shp %>% 
    # Rename columns to standardized names using non-standard evaluation
    # !!sym() converts string column names to symbols for use in dplyr
    rename("geo_id" = !!sym(geo_id_var),
           "n_black" = !!sym(black_var),
           "n_white" = !!sym(white_var),
           "n_tot" = !!sym(totpop_var)
           ) %>%
    # Keep only the geo_id columns and any other columns starting with "n_"
    select("geo_id", starts_with("n_")) %>%
    # Calculate derived variables
    mutate(n_other = n_tot - (n_black + n_white),
           year = year)
  # Transform coordinate reference system to WGS84 (EPSG:4326)
  # This is a standard geographic coordinate system using latitude/longitude
  shp <- sf::st_transform(shp, 4326)
  # Calculate area of each tract in square meters
  # st_area() returns area in the units of the coordinate system
  shp$geo_area_meters <- sf::st_area(shp)
  
  # Return cleaned dataset with standardized column order
  # Includes: year, geographic ID, population counts by race, area, and geometry
  return(shp %>% select("year", "geo_id", "n_tot", "n_black", "n_white", "n_other", "geo_area_meters", "geometry"))
}

# Clean and merge census block geographic and demographic data
clean_block_data <- function(shp, df, shp_b_id, df_b_id, var_prefix, df_n_black, df_n_white, drop_var="", year) {
  # Function parameters:
  # shp: spatial dataframe (sf object) containing block geometries
  # df: regular dataframe containing demographic data
  # shp_b_id: name of the block ID column in the spatial dataframe (as string)
  # df_b_id: name of the block ID column in the demographic dataframe (as string)
  # var_prefix: prefix string to identify population count columns in df
  # df_n_black: name of the Black population column in df (as string)
  # df_n_white: name of the White population column in df (as string)
  # drop_var: optional column name to remove from df (default: empty string)
  # year: year of the census data (added as metadata)
  
  # Clean the spatial dataframe
  # Keep only the block ID column and rename it to standard "geo_id"
  shp <- shp %>% select(!!sym(shp_b_id)) %>% rename("geo_id" = !!sym(shp_b_id))
  # Optional: remove unwanted column from demographic dataframe
  # Only executes if drop_var parameter is not empty
  if (drop_var!="") {df <- df %>% select(-!!sym(drop_var))}
  
  # Process demographic dataframe
  df <- df %>% 
    # Keep block ID and all columns starting with the specified prefix
    select(!!sym(df_b_id), starts_with(var_prefix)) %>%
    # Apply rowwise operations to calculate totals for each row
    rowwise() %>%
    # Sum all columns with the specified prefix to get total population
    # c_across() selects multiple columns for the sum() function
    mutate(n_tot = sum(c_across(starts_with(var_prefix))))
  
  # Further clean the demographic data
  df <- df %>%
    # Rename columns to standardized names
    rename("geo_id" = !!sym(df_b_id),
           "n_black" = !!sym(df_n_black),
           "n_white" = !!sym(df_n_white)) %>%
    # Remove the original prefix columns (no longer needed after summing)
    select(-starts_with(var_prefix)) %>%
    # Calculate population of other races/ethnicities
    mutate(n_other = n_tot - (n_black + n_white))
  
  # Merge spatial and demographic data
  # Left join ensures all geographic units are retained
  shp <- dplyr::left_join(shp, df, by="geo_id") 
  # Transform coordinate reference system to WGS84 (EPSG:4326)
  # Standard geographic coordinate system using latitude/longitude
  shp <- sf::st_transform(shp, 4326)
  # Calculate area of each block in square meters
  shp$geo_area_meters <- sf::st_area(shp)
  # Add year as metadata column
  shp$year <- year
  
  # Return the cleaned and merged spatial dataframe
  return(shp %>% select("year", "geo_id", "n_tot", "n_black", "n_white", "n_other", "geo_area_meters", "geometry"))
}


# fix broken geometries, if there are problems
fix_geo_if_broken <- function(shp) {
  if (min(sf::st_is_valid(shp)) == 0) {
    print("Fixing geometry...")
    return(sf::st_make_valid(shp))
  } else {
      return(shp)
    }
  }
```

Clean the data:

```{r}
# turn off spherical geometry (s2)
sf_use_s2(FALSE)

# load data that has the dates the historic districts were designated
# comes from here: https://planning.dc.gov/page/dc-historic-districts
# hd_data <- readr::read_csv("https://docs.google.com/spreadsheets/d/1Ajl1iAS0NRB7vk_UFDveeWzGkwf3tuiDo-zV9_wtzRM/gviz/tq?tqx=out:csv&sheet=data")
hd_data <- readr::read_csv("hd_data/data.csv")

# load the historic district boundary shape files
# comes from here: https://opendata.dc.gov/datasets/DCGIS::historic-districts/about 
hd_shp <- sf::st_read("Historic_Districts/Historic_Districts.shp")

# load the 2022 ward shape files
# comes from here: https://opendata.dc.gov/datasets/DCGIS::wards-from-2022/about
ward_shp <- sf::st_read("Wards_from_2022/Wards_from_2022.shp")

# load the zoning map:
# comes from here: https://opendata.dc.gov/datasets/DCGIS::zoning-boundaries-zoning-regulations-of-2016/about
zone_shp <- sf::st_read("zoning/Zoning_Boundaries_(Zoning_Regulations_of_2016).shp")

# load data at the tract level for 1960 (this is the lowest-geographic level I could find)
b60_shp <- load_clean_tracts("GISJOIN", "B58013", "B58011", "CA4001", 1960)
b60_shp <- fix_geo_if_broken(b60_shp)
# in an older version of this analysis, I ran everything using tracts;
# you can uncomment the lines below to load the tract data and do that
# b70_shp <- load_clean_tracts("GISJOIN", "CEB03", "CEB01", "CY7001", 1970) 
# b80_shp <- load_clean_tracts("GISJOIN", "C9D003", "C9D001", "C7L001", 1980)
# b90_shp <- load_clean_tracts("TRACTNO", "BLACK", "WHITE", "POPULATION", 1990)
# b00_shp <- load_clean_tracts("TRACTNO", "BLACK", "WHITE", "TOTAL", 2000)
# b10_shp <- load_clean_tracts("TRACT", "P0010004", "P0010003", "P0010001", 2010)
# b20_shp <- load_clean_tracts("TRACT", "P0010004", "P0010003", "P0010001", 2020)
invisible(gc())

# Load raw block data:
# b70_shp <- sf::st_read("block_shapes/US_block_1970/US_block_1970.shp")
# b70_shp <- b70_shp[b70_shp$STATE70=="11",]
# sf::st_write(b70_shp, "block_shapes/DC_block_1970/DC_block_1970.shp")
b70_shp <- sf::st_read("block_shapes/DC_block_1970/DC_block_1970.shp")
b80_shp <- sf::st_read("block_shapes/DC_block_1980/DC_block_1980.shp")
b90_shp <- sf::st_read("block_shapes/nhgis0092_shapefile_tl2000_110_block_1990/DC_block_1990.shp")
b00_shp <- sf::st_read("block_shapes/nhgis0092_shapefile_tl2000_110_block_2000/DC_block_2000.shp")
b10_shp <- sf::st_read("block_shapes/nhgis0092_shapefile_tl2010_110_block_2010/DC_block_2010.shp")
b20_shp <- sf::st_read("block_shapes/nhgis0092_shapefile_tl2020_110_block_2020/DC_block_2020.shp")

b70_df <- readr::read_csv("block_data/nhgis0093_ds96_1970_block.csv")
b80_df <- readr::read_csv("block_data/nhgis_ds104_1980_block_11.csv")
b90_df <- readr::read_csv("block_data/nhgis0092_ds120_1990_block.csv")
b00_df <- readr::read_csv("block_data/nhgis0092_ds147_2000_block.csv")
b10_df <- readr::read_csv("block_data/nhgis0092_ds172_2010_block.csv")
b20_df <- readr::read_csv("block_data/nhgis0092_ds258_2020_block.csv")

invisible(gc())

# 1970 block data has to be specially cleaned, see https://forum.ipums.org/t/race-ethnicity-data-at-a-block-level-from-1970/6178
b70_df$c_black <- b70_df$CM6001 + b70_df$CM6002
b70_df$c_other <- b70_df$CM6003 + b70_df$CM6004
b70_df$c_white <- b70_df$CM5001 + b70_df$CM5002 - b70_df$c_black - b70_df$c_other

# merge the data and the shapefiles and clean up the data:
b70_shp <- clean_block_data(b70_shp, b70_df, "GISJOIN", "GISJOIN", "c_", "c_black", "c_white", year=1970)
b80_shp <- clean_block_data(b80_shp, b80_df, "GISJOIN", "GISJOIN", "C9D0", "C9D002", "C9D001", year=1980)
b90_shp <- clean_block_data(b90_shp, b90_df, "GISJOIN", "GISJOIN", "EUY0", "EUY002", "EUY001", year=1990)
b00_shp <- clean_block_data(b00_shp, b00_df, "GISJOIN", "GISJOIN", "FYE0", "FYE002", "FYE001", year=2000)
b10_shp <- clean_block_data(b10_shp, b10_df, "GISJOIN", "GISJOIN", "H7X", "H7X003", "H7X002", "H7X001", year=2010)
b20_shp <- clean_block_data(b20_shp, b20_df, "GISJOIN", "GISJOIN", "U7J", "U7J003", "U7J002", "U7J001", year=2020)

# remove data we don't need anymore
rm(b70_df, b80_df, b90_df, b00_df, b10_df, b20_df)
invisible(gc())

# Merge historic district (HD) data onto HD shapefile, subset to only look at neighborhood HDs:
hd_shp <- dplyr::left_join(x = hd_shp, y = hd_data, by = "UNIQUEID")
hd_shp <- hd_shp[hd_shp$Neighborhood_HD==1,]

# convert to mercator projection
zone_shp <- sf::st_transform(zone_shp, 4326)
hd_shp <- sf::st_transform(hd_shp, 4326)
ward_shp <- sf::st_transform(ward_shp, 4326)

# fix any broken geometries:
zone_shp <- fix_geo_if_broken(zone_shp)
hd_shp <- fix_geo_if_broken(hd_shp)
ward_shp <- fix_geo_if_broken(ward_shp)
b60_shp <- fix_geo_if_broken(b60_shp)
b70_shp <- fix_geo_if_broken(b70_shp)
b80_shp <- fix_geo_if_broken(b80_shp)
b90_shp <- fix_geo_if_broken(b90_shp)
b10_shp <- fix_geo_if_broken(b10_shp)
b20_shp <- fix_geo_if_broken(b20_shp)


# combine shapes into one big object, remove individual objects:
geos_shp <- dplyr::bind_rows(b60_shp, b70_shp, b80_shp, 
                             b90_shp, b00_shp, b10_shp, b20_shp)
# create a truly unique block/tract ID:
geos_shp$geo_id <- paste0(geos_shp$year, "_", geos_shp$geo_id)

rm(b60_shp, b70_shp, b80_shp, b90_shp, b00_shp, b10_shp, b20_shp)

# list zones in the ZR16 data:
zones_list <- sort(unique(zone_shp$ZR16))
housing_zones <- zones_list[grep(x=zones_list, pattern = "^R|^MU")]
# subset zones to mostly-housing zones 
zone_shp <- zone_shp[zone_shp$ZR16 %in% housing_zones,]

# create simplified labels
zone_shp$ZR16_simple <- "Other"
zone_shp$ZR16_simple[grep(x=zone_shp$ZR16, pattern="^RA-")] <- "Apartment zones"
zone_shp$ZR16_simple[grep(x=zone_shp$ZR16, pattern="^R-")] <- "Residential zones"
zone_shp$ZR16_simple[grep(x=zone_shp$ZR16, pattern="^RF-")] <- "Residential flat zones"
zone_shp$ZR16_simple[grep(x=zone_shp$ZR16, pattern="^MU-")] <- "Mixed use zones"

```


Plot the simplified zoning map with historic districts overlaid:

```{r}
# show on a map:
factpal <- colorFactor(palette = "Set1", domain = zone_shp$ZR16_simple)

leaflet(zone_shp) %>%
  addProviderTiles(providers$CartoDB.Positron) %>%
  addPolygons(group="ZR16 zones",
              fillColor = ~factpal(ZR16_simple), # Apply the color function
              fillOpacity = 0.7,
              weight = 1,
              opacity = 1,
              color = "white",
              label=~ZR16,
              highlightOptions = highlightOptions(weight = 3,
                                                  color = "white",
                                                  bringToFront = TRUE
        )
  ) %>%
  addPolygons(group= "HDs",
              data=hd_shp,
              fillColor = "grey", 
              fillOpacity = 0.5,
              weight = 1,
              opacity = 1,
              color = "white",
              label=~LABEL,
              highlightOptions = highlightOptions(weight = 3,
                                                  color = "white",
                                                  bringToFront = FALSE
        ))  %>%
  addLegend(pal = factpal, values = ~ZR16_simple, opacity = 0.7, title = NULL,
    position = "bottomright") %>%
  addLayersControl(
    overlayGroups = c("ZR16 zones", "HDs"),
    options = layersControlOptions(collapsed = FALSE)
  )

```


Calculate the total amount of residential and MU land in DC, then see how much is covered by HDs in each year:

```{r}
invisible(gc())
# get each zone's acreage:
zone_shp$area_meters <- sf::st_area(zone_shp)
zone_shp$area_acres <- as.vector(zone_shp$area_meters * 0.000247105)
total_zone_acres <- sum(zone_shp$area_acres, na.rm=T)

# get shape areas:
hd_shp$area_meters <- sf::st_area(hd_shp)
hd_shp$area_acres <- as.vector(hd_shp$area_meters * 0.000247105)

years <- c(1960, 1970, 1980, 1990, 2000, 2010, 2025)
land_areas <- rep(NA, length(years))
counter <- 1
for (year in years) { # Land area covered by HDs by year:
  land_area <- sum(hd_shp$area_acres[hd_shp$desig_date < year])
  land_areas[counter] <- land_area
  counter <- counter + 1
}

p <- data.frame(years, land_areas, round(100*land_areas / total_zone_acres,0))
names(p) <- c("Year", 
              "Area covered by by Historic Districts, in Acres",
              "Percent of 2016 residential zone covered by Neighborhood HD")
plot1 <-
  ggplot(p, 
       aes(x=Year, 
           y=`Area covered by by Historic Districts, in Acres`)) + 
  geom_bar(stat = "identity", fill="#0f9535") +
  geom_text(aes(label = round(`Area covered by by Historic Districts, in Acres`, 0), vjust = -1.7)) +
  ylab("Acres") +
  theme_minimal() +
  ggtitle('Acres covered by "neighborhood historic districts"\nhas steadily increased over time')

plot2 <-
  ggplot(p, 
       aes(x=Year, 
           y=`Percent of 2016 residential zone covered by Neighborhood HD`)) + 
  geom_line(color="#0f9535", size=.75) +
  geom_point(color="#0f9535") +
  geom_text(aes(label = paste0(`Percent of 2016 residential zone covered by Neighborhood HD`, "%")), vjust = -1.7) +
  theme_minimal() +
  ylab("Percent") +
  ggtitle('And the % of residential area covered\nby HDs has more than doubled since 1980')

grid.arrange(plot1, plot2, ncol = 2) # Arranges p1 and p2 in two columns

rm(p, plot1, plot2, counter, land_area, housing_zones, 
   land_area, land_areas, total_zone_acres)
```


Plot the % of HDs that are apartment zones, vs mixed use, vs residential flat, etc.

```{r}
hd_zones_info <- 
  sf::st_intersection(x = hd_shp, y = zone_shp) %>%
  mutate(area = sf::st_area(.)) %>%
  group_by(ZR16_simple) %>%
  summarize(area_sq_meters = sum(area, na.rm=T)) %>%
  sf::st_drop_geometry(.) %>%
  ungroup() %>%
  mutate(pct = area_sq_meters / sum(area_sq_meters, na.rm=T),
         type = "In an HD") %>%
  select(-area_sq_meters)
invisible(gc())

other_zones_info <- 
  sf::st_difference(x = zone_shp, y = hd_shp) %>%
  mutate(area = sf::st_area(.)) %>%
  group_by(ZR16_simple) %>%
  summarize(area_sq_meters = sum(area, na.rm=T)) %>%
  sf::st_drop_geometry(.) %>%
  ungroup() %>%
  mutate(pct = area_sq_meters / sum(area_sq_meters, na.rm=T),
         type = "Not in an HD") %>%
  select(-area_sq_meters)
invisible(gc())

zones_plot <- dplyr::bind_rows(hd_zones_info, other_zones_info)
zones_plot$pct <- round(as.vector(zones_plot$pct) * 100, 0)
zones_plot$ZR16_simple <- factor(zones_plot$ZR16_simple, 
                                 levels = c("Residential flat zones", 
                                            "Residential zones", 
                                            "Apartment zones",
                                            "Mixed use zones"))

ggplot(zones_plot, aes(x = ZR16_simple, y = pct, fill=type)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(
    aes(label = pct, y = pct + 0.07),
    position = position_dodge(0.9),
    vjust = -.05
  ) +
  labs(title = "More zone area in Historic Districts is Residential Flat (RF), less is Residential (R)", 
       x = "Zone type", y = "Percent", fill="")

rm(hd_zones_info, other_zones_info, zones_plot)
invisible(gc())

```

When were different historic districts designated?

```{r}

hd_shp$desig_decade <- hd_shp$desig_date - (hd_shp$desig_date %% 10)

pal <- colorNumeric(palette = "viridis", domain = hd_shp$desig_decade)

leaflet() %>% 
  addProviderTiles(providers$CartoDB.Positron) %>%
  addPolygons(data=hd_shp,
              fillColor = ~pal(hd_shp$desig_decade), 
              fillOpacity = 0.9,
              weight = 1,
              opacity = 1,
              color = "white",
              label=~paste0(LABEL, ": ", desig_date),
              highlightOptions = highlightOptions(weight = 3,
                                                  color = "white",
                                                  bringToFront = FALSE
        ) 
  ) %>%
  addLegend(pal = pal, values = hd_shp$desig_decade, opacity = 0.7, 
             labFormat = labelFormat(big.mark = ""),
            title = "HD created in this decade:")


```



We'll remove some very small HDs for the next part (like HDs that are a single circle):

```{r}
# Drop some very small HDs that are like a single circle
# We just dropped anything smaller than 10 acres
hd_shp <-
  hd_shp %>%
  filter(!(LABEL %in% c("Emerald St HD",
                       "Grant Rd HD",
                       "Mount Vernon Triangle HD",
                       "Grant Circle HD",
                       "Union Market"
                       )))

```




# Demographic change analysis

Now let's look and see how HDs changed over time, in terms of % black residents and % white residents, compared to nearby neighborhoods (groups of blocks) that were not in HDs.

This will have a few steps:

1. Take a given HD.
2. Get the intersection of the HD with census tracts (in 1960) and blocks (in 1970 to 2020). If at least X% of the census tract area is in the HD, we'll count it as part of the HD.
3. Create a buffer around the HD of distance Y. Run another intersection with the census tracts/blocks and that buffer. Count any tracts/blocks that touch the buffer but are not in an HD as comparison tracts. 
4. Note the % of white and black residents in each HD and those HDs comparison tracts/blocks.
5. See how those respective percentages change over time. 



Function to find which tracts/blocks are in which HDs:

```{r}
# Get geographic units (tracts/blocks) within Historic Districts and calculate summary statistics
get_geos_in_hd <- function(shp, min_pct, year) {
  # Function parameters:
  #' @param shp: the tract or block shapefile (an sf shapefile object) containing demographic data
  #' @param min_pct: minimum % of the tract/block that must be in the HD to count as part of the HD 
  #          (decimal between 0 and 1, e.g., 0.5 for 50%)
  #' @param year: the year of analysis (integer like 1980)
  # Note: This function assumes 'hd_shp' exists in the global environment as the Historic Districts shapefile
  
  # STEP 1: Spatial intersection analysis
  # Find the intersection between census units and historic districts
  # This creates new polygons where census units overlap with HDs
  i <- sf::st_intersection(x=shp, y=hd_shp)
  
  # Calculate the area of each intersection polygon in square meters
  i$i_area <- sf::st_area(i)
  
  # Calculate what percentage of the original census unit area falls within each HD
  # as.vector() removes units to get numeric values for comparison
  i$pct_of_geo_area <- as.vector(i$i_area / i$geo_area_meters)
  
  # STEP 2: Filter geographic units based on minimum percentage threshold
  # Keep only census units where a sufficient portion (> min_pct) falls within an HD
  # Select relevant columns for analysis
  geos_in_hd <- i[i$pct_of_geo_area > min_pct, 
                    c("year", "geo_id", "LABEL",
                      "n_tot", "n_black", "n_white", "n_other",
                      "desig_date", "pct_of_geo_area")]
  
  # Recalculate area for the filtered intersection polygons
  geos_in_hd$geo_area <- sf::st_area(geos_in_hd)
  
  # STEP 3: Create summary statistics by Historic District
  geos_in_hd_summary <-
    geos_in_hd %>%
    # Calculate prorated population counts based on the percentage of area in each HD
    # This accounts for partial overlaps (e.g., if 60% of a tract is in an HD, 
    # count 60% of its population toward that HD)
    mutate(n_tot_prorated = n_tot * pct_of_geo_area,
           n_black_prorated = n_black * pct_of_geo_area,
           n_white_prorated = n_white * pct_of_geo_area,
           n_other_prorated = n_other * pct_of_geo_area) %>%
    # Select columns needed for summary
    select("year", "LABEL", "geo_id", starts_with("n_"), "desig_date", "geo_area") %>%
    # Group by Historic District label to aggregate data
    group_by(LABEL) %>%
    # Summarize data for each Historic District
      summarise(
                # Raw population counts (sum of all units in HD, regardless of partial overlap)
                n_tot = sum(n_tot, na.rm=T),
                n_black = sum(n_black, na.rm=T),
                n_white = sum(n_white, na.rm=T),
                n_other = sum(n_other, na.rm=T),
                # Prorated population counts (adjusted for partial overlaps)
                n_tot_prorated = sum(n_tot_prorated, na.rm=T),
                n_black_prorated = sum(n_black_prorated, na.rm=T),
                n_white_prorated = sum(n_white_prorated, na.rm=T),
                n_other_prorated = sum(n_other_prorated, na.rm=T),
                # HD designation year (latest designation date if multiple)
                desig_year = max(desig_date, na.rm=T),
                # Total geographic area of the HD
                geo_area = sum(geo_area, na.rm=T)) %>%
    # Add derived variables
    mutate(desig_yet = ifelse(desig_year<year, 1, 0), 
           year = year,
           pop_dens = n_tot / geo_area)
  
    # STEP 4: Prepare return object
    # Create a list with two components:
    # 1. Detailed data for each geographic unit within HDs (with spatial geometry)
    # 2. Summary statistics by HD (without spatial geometry for easier data manipulation)
    rv = list("geos_in_hd"=geos_in_hd, "summary"=sf::st_drop_geometry(geos_in_hd_summary))
    
    return(rv)
}


```

Function to find which tracts/blocks are nearby but not inside the HDs, using a simple geographic buffer:

```{r}

get_neighbor_geos <- function(hd_shp, geo_shp, buffer_dist, geos_in_hd, remove_geo_thresh, year) {
  #' Get neighboring geographic units (tracts/blocks) around Historic Districts (HDs)
  #'
  #' This function identifies geographic units that are adjacent to Historic Districts
  #' by creating buffers around HDs and finding intersecting geographic units, while
  #' excluding units already classified as within HDs and those where HDs occupy
  #' a large portion of the geographic unit.
  #'
  #' @param hd_shp sf object containing Historic District boundaries
  #' @param geo_shp sf object containing geographic units (census tracts/blocks)
  #' @param buffer_dist numeric buffer distance (in same units as CRS) around HDs
  #' @param geos_in_hd list containing geographic units already within HDs
  #' @param remove_geo_thresh numeric threshold (0-1) for removing geos with large HD overlap
  #' @param year numeric year for designation comparison
  #'
  #' @return list with three elements: buffers, neighbor_geos, neighbor_geos_summary
  #' 
  # STEP 1: Create buffer zones around Historic Districts
  # Creates a buffer of specified distance around each HD boundary
  # This defines the "neighborhood" area we're interested in
  b <- sf::st_buffer(hd_shp, dist = buffer_dist)
  # STEP 2: Find geographic units that intersect with HD buffers
  # This identifies all census tracts/blocks that fall within or overlap
  # the buffer zones around Historic Districts
  i <- sf::st_intersection(x=geo_shp, y=b)
  # STEP 3: Remove geographic units already classified as within an HD
  # Excludes any tracts/blocks that have already been identified as being
  # inside Historic District boundaries (not just neighboring them)
  i <- i[!(i$geo_id %in% geos_in_hd),]
  # STEP 4: Calculate HD area coverage within each geographic unit
  # This section removes geographic units where Historic Districts occupy
  # more than the specified threshold percentage of the unit's area
  
  # Calculate total area of each Historic District
  hd_shp$area_meters <- sf::st_area(hd_shp)
  # Find intersection between all geographic units and Historic Districts
  # This shows where HDs actually overlap with census tracts/blocks
  hd_geo <- sf::st_intersection(x=geo_shp, y=hd_shp)
  # Calculate the area of HD-geography intersection
  hd_geo$intersect_area <- sf::st_area(hd_geo)
  # Calculate what percentage of each HD falls within each geographic unit
  # This helps identify cases where most of an HD is contained within a single tract/block
  hd_geo$pct_area <- as.vector(hd_geo$intersect_area / hd_geo$area_meters)
  # Identify geographic units to remove (those with HD coverage above threshold)
  # These are units where Historic Districts occupy too large a portion to be
  # considered merely "neighboring" - they likely contain significant HD area
  geos_to_remove <- hd_geo$geo_id[hd_geo$pct_area > remove_geo_thresh]
  # Remove the problematic geographic units from our neighboring list
  neighboring_geos <- i[!(i$geo_id %in% geos_to_remove),]
  
  # STEP 5: Create final neighboring geographic units dataset
  # Get the full geographic data for the identified neighboring units
  neighboring_geos <- geo_shp[geo_shp$geo_id %in% neighboring_geos$geo_id,]
  # Add HD information (label and designation date) to neighboring geographic units
  # This links each neighboring unit to its associated Historic District(s)
  neighboring_geos <- dplyr::left_join(neighboring_geos, 
                                         sf::st_drop_geometry(i[,c("geo_id", "LABEL", "desig_date")]),
                                         by="geo_id")
  
  # STEP 6: Add area variable:
  neighboring_geos$geo_area <- sf::st_area(neighboring_geos)
  
  # STEP 7: Create summary statistics by Historic District
  # Aggregate demographic data across all neighboring units for each HD
  neighbor_geos_summary <-
    sf::st_drop_geometry(neighboring_geos) %>%
    group_by(LABEL) %>%
      summarise(n_tot = sum(n_tot, na.rm=T),
                n_black = sum(n_black, na.rm=T),
                n_white = sum(n_white, na.rm=T),
                n_other = sum(n_other, na.rm=T),
                desig_year = max(desig_date, na.rm=T),
                tot_area = sum(geo_area, na.rm=T)) %>%
    mutate(desig_yet = ifelse(desig_year<year, 1, 0),
           year = year,
           pop_dens = n_tot / tot_area)
  
  # STEP 8: Return comprehensive results
  rv = list("buffers" = b, 
            "neighbor_geos" = neighboring_geos, 
            "neighbor_geos_summary" = neighbor_geos_summary)
  
  return(rv)
}
```



Function to map those tracts/blocks and see if everything looks good:

```{r}

plot_geos <- function(geo_shp, nearby_geos_shp, geos_in_hds, buffers) {
  rv <-
    leaflet() %>%
  addProviderTiles(providers$CartoDB.Positron) %>%
  addPolygons(group='buffers', data=buffers) %>%
  addPolygons(group= "geos labeled as near HDs",
              data=nearby_geos_shp,
              fillColor = "skyblue", 
              fillOpacity = 0.7,
              weight = 1,
              opacity = 1,
              color = "white",
              label=~paste0("Geo: ", geo_id, "; HD neighbor: ", LABEL),
              highlightOptions = highlightOptions(weight = 3,
                                                  color = "white",
                                                  bringToFront = FALSE
        ) 
  ) %>%
    addPolygons(group= "geos labeled as in HDs",
              data=geo_shp[geo_shp$geo_id %in% geos_in_hds, ],
              fillColor = "limegreen", 
              fillOpacity = 0.7,
              weight = 1,
              opacity = 1,
              color = "white",
              label=~geo_id,
              highlightOptions = highlightOptions(weight = 3,
                                                  color = "white",
                                                  bringToFront = FALSE
        ) 
  ) %>%
  addPolygons(group= "HDs",
              data=hd_shp,
              fillColor = "hotpink", 
              fillOpacity = 0.7,
              weight = 1,
              opacity = 1,
              color = "white",
              label=~LABEL,
              highlightOptions = highlightOptions(weight = 3,
                                                  color = "white",
                                                  bringToFront = FALSE
        ) 
  ) %>%
  addLayersControl(
    overlayGroups = c("geos labeled as near HDs", "geos labeled as in HDs", "HDs", "buffers"),
    options = layersControlOptions(collapsed = FALSE)
  )
  
  return(rv)
}
```

Function to plot data in a grid, one for each HD:

```{r}
make_lineplot <- function(depend_var, title, df) {
  rv <-
    ggplot(data=meth1_df, aes(x=year, y=!!sym(depend_var), color=as.factor(treatment))) + 
  geom_point() + 
  geom_line() +
  geom_vline(data = meth1_df,
             aes(xintercept = desig_date), 
             color = "black", 
             linetype = "dashed", 
             size = 1) +
  ggtitle(depend_var) +
    facet_grid(rows = vars(LABEL), scales = "free_y")
  
  return(rv)
}

```


First, find which blocks/tracts are in which HDs:

```{r}
# find which blocks/tracts are in which HDs, store that in one big object called hd_geos_shp
mp = 0.25 
for (y in sort(unique(geos_shp$year))) {
  if (y == min(unique(geos_shp$year))) {
    hd_geos_shp <- 
      get_geos_in_hd(geos_shp %>% filter(year==y), min_pct = mp, year = y)$geos_in_hd
  } else(
    hd_geos_shp <- 
      dplyr::bind_rows(hd_geos_shp,
                       get_geos_in_hd(geos_shp %>% filter(year==y), min_pct = mp, year = y)$geos_in_hd)
  )
}
invisible(gc())
```


Now we'll try two different approaches to finding "comparison" blocks/tracts:

* Buffer / geographic nearness approach
* Best geographically-proximate match approach


```{r}
# Find which blocks/tracts are within a certain buffer radius of each HD
# the buffer distance is in decimal degrees
buff_dist = .008
threshold = .1
for (y in sort(unique(geos_shp$year))) {
  items <- get_neighbor_geos(hd_shp=hd_shp, 
                        geo_shp=geos_shp %>% filter(year==y), 
                        buffer_dist=buff_dist, 
                        geos_in_hd=unique(hd_geos_shp$geo_id),
                        threshold, 
                        y)
  if (y == min(unique(geos_shp$year))) {
    near_geos_shp <- items$neighbor_geos
    buffers <- items$buffers %>% mutate(year=y)
  } else {
    near_geos_shp <- dplyr::bind_rows(near_geos_shp, items$neighbor_geos)
    buffers <- dplyr::bind_rows(buffers, 
                                items$buffers %>% mutate(year=y))
  }
  invisible(gc())
}

rm(items)

y = 1960
plot_geos(geos_shp %>% filter(year==y), 
          near_geos_shp %>% filter(year==y), 
          hd_geos_shp$geo_id[hd_geos_shp$year==y],
          buffers %>% filter(year==y))
y = 2020
plot_geos(geos_shp %>% filter(year==y), 
          near_geos_shp %>% filter(year==y), 
          hd_geos_shp$geo_id[hd_geos_shp$year==y],
          buffers %>% filter(year==y))
```

Now we'll conduct the analysis:

```{r, fig.height=75}
# create a big df on which we'll run the regressions for method/approach 1
meth1_df <- 
  dplyr::bind_rows(
    hd_geos_shp %>% 
      select("year", "geo_id", "LABEL", "n_tot", 
                            "n_black", "n_white", "n_other", 
                            "desig_date", "geometry") %>%
      mutate(treatment=1),
    near_geos_shp %>% 
      select("year", "geo_id", "LABEL", "n_tot", 
                            "n_black", "n_white", "n_other", 
                            "desig_date", "geometry") %>%
      mutate(treatment=0)
    )

meth1_df <- 
  meth1_df %>%
  # create additional derived variables 
  mutate(area = sf::st_area(.)) %>%
  # drop geometry
  sf::st_drop_geometry(.) %>%
  # summarize the data
  group_by(LABEL, year, treatment) %>%
  summarise(n_tot = sum(n_tot, na.rm=T),
            n_black = sum(n_black, na.rm=T),
            n_white = sum(n_white, na.rm=T),
            desig_date = mean(desig_date, na.rm=T),
            area = sum(area, na.rm=T)) %>%
  mutate(pop_dens = as.vector(n_tot / area),
         pct_black = n_black / n_tot,
         pct_white = n_white / n_tot,
         post = ifelse(desig_date < year, 1, 0),
         unit_id = paste(LABEL, treatment)) %>%
  ungroup() %>%
  # create a unique numeric ID for each treatment and control unit; we need this
  # for the DiD package
  group_by(LABEL, treatment) %>%
  mutate(numeric_id = cur_group_id(),
         gname = ifelse(treatment==1, ceiling(desig_date / 10) * 10, 0)) %>%
  ungroup() %>%
  arrange(LABEL, year, treatment)


diff_in_diff <- 
  lm(pop_dens  ~ treatment + post + treatment:post + unit_id + year, 
     data = meth1_df, weights=n_tot)
summary(diff_in_diff)


# Alternate specification:
# https://bcallaway11.github.io/did/articles/did-basics.html#an-example-with-real-data
# https://cran.r-project.org/web/packages/did/vignettes/pre-testing.html
attgt <- did::att_gt(yname = "pop_dens",
             gname = "gname",
             idname = "numeric_id",
             tname = "year",
             xformla = ~1,
             data = meth1_df[!is.na(meth1_df$pop_dens),],
             allow_unbalanced_panel = T,
             weightsname="n_tot"
             )
print(summary(attgt))
group_effects <- aggte(attgt, type = "group", na.rm=T)
print(summary(group_effects))
  
      
make_lineplot(depend_var = "pct_white", meth1_df)

```



Best geographically-proximate match approach

```{r}
# get block centroids, calculate distance between all points
get_distances <- function(shp) {
  points <- sf::st_centroid(shp)
  distances <- sf::st_distance(points)
  
  return(distances)
}

# confirm areas:
geos_shp$geo_area_meters <- sf::st_area(geos_shp) 
# calculate normalized variables
geos_shp <-
  geos_shp %>%
  group_by(year) %>%
  mutate(n_tot_norm = n_tot / max(n_tot, na.rm=T),
         pop_dens = n_tot / geo_area_meters,
         pop_dens_norm = pop_dens / max(pop_dens, na.rm=T),
         geo_area_meters_norm = geo_area_meters / max(geo_area_meters, na.rm=T),
         pct_black = n_black / n_tot,
         pct_white = n_white / n_tot) %>%
  ungroup()

# get the distances between each block in each year
dists <- list("1960"=NA, "1970"=NA, "1980"=NA, "1990"=NA, "2000"=NA, "2010"=NA, "2020"=NA)
for (y in sort(unique(geos_shp$year))) {
  invisible(gc())
  print(paste("on year", y))
  dists[[as.character(y)]] <- get_distances(geos_shp %>% filter(year==y))
}

# loop through each block in each HD and year and find the N closest blocks
geos_df <- sf::st_drop_geometry(geos_shp)
n = 40
matches_df <- data.frame("hd_id"=NA, "match_id"=NA)
for (y in sort(unique(geos_df$year))) {
  invisible(gc())
  print(paste("on", y))
  temp_df <- geos_df %>% filter(year==y)
  temp_geos_in_hds <- sort(unique(hd_geos_shp$geo_id[hd_geos_shp$year==y]))
  # get indexes of the blocks that are in HDs
  block_indexes_in_hds <- match(temp_geos_in_hds, temp_df$geo_id)
  # set the distances between any two blocks in HDs to be a high value, so 
  # we never match two blocks in any two HDs:
  for (i in blocks_in_hds) {
    for (j in blocks_in_hds) {
      dists[[as.character(y)]][i, j] <- 9999999
    }
  }
  diag(dists[[as.character(y)]]) <- 9999999
  # get a matrix with the indices of the n closest blocks for each row
  closest_blocks <- apply(dists[[as.character(y)]], 1, function(x) {order(x)[1:n]})
  # now loop through each hd block...
  for (b in block_indexes_in_hds) {
    indices_of_n_closest_blocks <- closest_blocks[, b]
    # and get the data rows corresponding to those closest blocks
    closest_blocks_df <- temp_df[indices_of_n_closest_blocks, ]
    # as well as the data row corresponding to the HD block we're looking at
    hd_block_df <- temp_df[b,]
    # which we need to make the same size as the comparison data frame
    replicated_row <- hd_block_df[rep(1, nrow(closest_blocks_df)), ]
    # now subtract the HD blocks values from all of the potential matching blocks
    diff <- 
      abs(closest_blocks_df[,c("n_tot_norm", "pop_dens_norm", 
                         "geo_area_meters_norm", "pct_black", "pct_white")] - 
      replicated_row[,c("n_tot_norm", "pop_dens_norm", 
                         "geo_area_meters_norm", "pct_black", "pct_white")])
    # sum to find the row with the smallest diff
    diff$diff <- rowSums(diff)
    # get the index of the row with the smallest diff
    match_index <- which.min(diff$diff)
    match_geo_id <- closest_blocks_df$geo_id[match_index]
    # add a row to record we found the closest match!
    matches_df <- rbind(matches_df, c(hd_block_df$geo_id[1], match_geo_id))
  }
}
```








